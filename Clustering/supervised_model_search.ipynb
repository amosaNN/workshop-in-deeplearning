{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from random import randint\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import plotting_funcs as pf\n",
    "import preprocessing as prep\n",
    "import clustering_model as cm\n",
    "import config as conf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16, 2) (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('x_balanced_sample_16.npy')\n",
    "y = np.load('y_balanced_sample_16.npy')\n",
    "types = np.array([conf.wells_to_genetype_dict[well] for well in y])\n",
    "y_letter = np.array([well[:1] for well in y])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "#labs = le.fit_transform(y)\n",
    "#labs_by_letter = le.fit_transform(y_letter)\n",
    "labs_by_type = le.fit_transform(types)\n",
    "labs_by_type = to_categorical(labs_by_type)\n",
    "X_XY = X[:,:,:2]\n",
    "X_added = prep.add_transformations(X)\n",
    "print(X_XY.shape , labs_by_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x(train,test):\n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train.reshape(-1, train.shape[-1])).reshape(train.shape)\n",
    "    test = scaler.transform(test.reshape(-1, test.shape[-1])).reshape(test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params permanent\n",
    "input_dim = X_XY.shape[-1]\n",
    "num_labels = len(np.unique(types))\n",
    "timesteps = X_XY.shape[-2]\n",
    "\n",
    "#model params to optimize\n",
    "n_filters_ = [64,64,32] #can vary in length (>1)\n",
    "n_units_ = [64,8]\n",
    "kernel_size_ = 12 \n",
    "pool_size_ = 8 # 8 equals flatten of 16\n",
    "\n",
    "#fit params permanent\n",
    "optimizer='adam'\n",
    "loss = 'categorical_crossentropy' # need label encoded labels\n",
    "epochs=100\n",
    "save_dir='results/tmp'\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "batch_size=256 # not really interesting to optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here should be param dicts and for loop over options\n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True,random_state=42)\n",
    "results = []\n",
    "#second iteration over best options that are different enough to try again\n",
    "n_filters_vec = [[128,64,64,32],[64,64,0,0],[64,64,32,0]] \n",
    "n_units_vec = [[128,16],[64,8]]\n",
    "kernel_size_vec = [8,12,16] \n",
    "pool_size_vec = [8,16] # 8 equals latent of 16, 16 equals latent of 8\n",
    "#total = 3*2*3*2 = 36\n",
    "\n",
    "iii=0\n",
    "for pool_size in pool_size_vec:\n",
    "    for kernel_size in kernel_size_vec:\n",
    "        for n_units in n_units_vec:\n",
    "            for n_filters in n_filters_vec:\n",
    "                val_accs = []\n",
    "                val_aucs = []\n",
    "                for index, (train_indices, val_indices) in enumerate(skf.split(X_XY, y)):\n",
    "                    print(\"fold \" + str(index+1) + \"/\" + str(N_SPLITS) + \"...\")\n",
    "                    X_train, X_val = preprocess_x(X_XY[train_indices], X_XY[val_indices])\n",
    "                    y_train, y_val = labs_by_type[train_indices], labs_by_type[val_indices]\n",
    "\n",
    "                    classifier_model = None\n",
    "                    classifier_model = cm.temporal_classifier(input_dim,num_labels,timesteps,n_filters,kernel_size,pool_size,n_units)\n",
    "                    classifier_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy',tf.keras.metrics.AUC(multi_label = True,name = 'auc')])\n",
    "                    \n",
    "                    t0 = time()\n",
    "                    history = classifier_model.fit(X_train, y_train,validation_data=(X_val,y_val) , batch_size=batch_size, epochs=epochs, verbose=0, callbacks=es)\n",
    "                    print('Pretraining time: ', time() - t0)\n",
    "                    \n",
    "                    _,train_acc,train_auc = classifier_model.evaluate(X_train, y_train, verbose=0)\n",
    "                    _,test_acc,test_auc = classifier_model.evaluate(X_val, y_val, verbose=0)\n",
    "                    print('accuracy: Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "                    print('auc: Train: %.3f, Test: %.3f' % (train_auc, test_auc))\n",
    "                    val_aucs.append(test_auc)\n",
    "                    val_accs.append(test_acc)\n",
    "                iii+=1\n",
    "                print(iii)\n",
    "                print('mean validation: Accuracy: %.3f, Auc: %.3f' % (np.mean(val_accs), np.mean(val_aucs)))\n",
    "                results.append([np.mean(val_accs),np.mean(val_aucs),pool_size,kernel_size,n_units[0],n_units[1],n_filters[0],n_filters[1],n_filters[2],n_filters[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('kfold_cv_results.npy',np.array(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['accuracy','AUC','pool_size','kernel_size','lstm1','lstm2','conv1','conv2','conv3','conv4']\n",
    "results_df = pd.DataFrame(results, columns = col_names)\n",
    "results_df['auc2acc'] = 2*results_df['accuracy']+results_df['AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>pool_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>lstm1</th>\n",
       "      <th>lstm2</th>\n",
       "      <th>conv1</th>\n",
       "      <th>conv2</th>\n",
       "      <th>conv3</th>\n",
       "      <th>conv4</th>\n",
       "      <th>auc2acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4584</td>\n",
       "      <td>0.759117</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.675917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.759338</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.659938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.756715</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.656915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.757122</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.655722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4487</td>\n",
       "      <td>0.756221</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.653621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.651884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.754627</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.646427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4468</td>\n",
       "      <td>0.752243</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.645843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.755277</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.642277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.754475</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.640875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.749586</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.640786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.747220</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.640220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4453</td>\n",
       "      <td>0.749075</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.749298</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.639498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.745599</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.4443</td>\n",
       "      <td>0.749532</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.4431</td>\n",
       "      <td>0.751306</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.637506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.752087</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.636887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.4442</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.635622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.749056</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.629256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.747229</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.628829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4406</td>\n",
       "      <td>0.747339</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.747068</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.627468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4415</td>\n",
       "      <td>0.744226</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.627226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.746274</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.624074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.4385</td>\n",
       "      <td>0.746637</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.623637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.747433</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.622833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.742253</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.622653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.750280</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.622080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4361</td>\n",
       "      <td>0.747863</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.620063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.4387</td>\n",
       "      <td>0.741875</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.619275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4357</td>\n",
       "      <td>0.742599</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.613999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.741319</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.606919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.4323</td>\n",
       "      <td>0.740923</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>1.605523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.739915</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.604115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.735619</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.596219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       AUC  pool_size  kernel_size  lstm1  lstm2  conv1  conv2  \\\n",
       "12    0.4584  0.759117          8           16    128     16    128     64   \n",
       "18    0.4503  0.759338         16            8    128     16    128     64   \n",
       "6     0.4501  0.756715          8           12    128     16    128     64   \n",
       "24    0.4493  0.757122         16           12    128     16    128     64   \n",
       "10    0.4487  0.756221          8           12     64      8     64     64   \n",
       "13    0.4497  0.752484          8           16    128     16     64     64   \n",
       "7     0.4459  0.754627          8           12    128     16     64     64   \n",
       "14    0.4468  0.752243          8           16    128     16     64     64   \n",
       "0     0.4435  0.755277          8            8    128     16    128     64   \n",
       "1     0.4432  0.754475          8            8    128     16     64     64   \n",
       "28    0.4456  0.749586         16           12     64      8     64     64   \n",
       "25    0.4465  0.747220         16           12    128     16     64     64   \n",
       "5     0.4453  0.749075          8            8     64      8     64     64   \n",
       "21    0.4451  0.749298         16            8     64      8    128     64   \n",
       "29    0.4466  0.745599         16           12     64      8     64     64   \n",
       "32    0.4443  0.749532         16           16    128     16     64     64   \n",
       "26    0.4431  0.751306         16           12    128     16     64     64   \n",
       "30    0.4424  0.752087         16           16    128     16    128     64   \n",
       "27    0.4442  0.747222         16           12     64      8    128     64   \n",
       "8     0.4401  0.749056          8           12    128     16     64     64   \n",
       "3     0.4408  0.747229          8            8     64      8    128     64   \n",
       "4     0.4406  0.747339          8            8     64      8     64     64   \n",
       "16    0.4402  0.747068          8           16     64      8     64     64   \n",
       "11    0.4415  0.744226          8           12     64      8     64     64   \n",
       "19    0.4389  0.746274         16            8    128     16     64     64   \n",
       "31    0.4385  0.746637         16           16    128     16     64     64   \n",
       "17    0.4377  0.747433          8           16     64      8     64     64   \n",
       "35    0.4402  0.742253         16           16     64      8     64     64   \n",
       "2     0.4359  0.750280          8            8    128     16     64     64   \n",
       "9     0.4361  0.747863          8           12     64      8    128     64   \n",
       "22    0.4387  0.741875         16            8     64      8     64     64   \n",
       "15    0.4357  0.742599          8           16     64      8    128     64   \n",
       "20    0.4328  0.741319         16            8    128     16     64     64   \n",
       "33    0.4323  0.740923         16           16     64      8    128     64   \n",
       "34    0.4321  0.739915         16           16     64      8     64     64   \n",
       "23    0.4303  0.735619         16            8     64      8     64     64   \n",
       "\n",
       "    conv3  conv4   auc2acc  \n",
       "12     64     32  1.675917  \n",
       "18     64     32  1.659938  \n",
       "6      64     32  1.656915  \n",
       "24     64     32  1.655722  \n",
       "10      0      0  1.653621  \n",
       "13      0      0  1.651884  \n",
       "7       0      0  1.646427  \n",
       "14     32      0  1.645843  \n",
       "0      64     32  1.642277  \n",
       "1       0      0  1.640875  \n",
       "28      0      0  1.640786  \n",
       "25      0      0  1.640220  \n",
       "5      32      0  1.639675  \n",
       "21     64     32  1.639498  \n",
       "29     32      0  1.638799  \n",
       "32     32      0  1.638132  \n",
       "26     32      0  1.637506  \n",
       "30     64     32  1.636887  \n",
       "27     64     32  1.635622  \n",
       "8      32      0  1.629256  \n",
       "3      64     32  1.628829  \n",
       "4       0      0  1.628539  \n",
       "16      0      0  1.627468  \n",
       "11     32      0  1.627226  \n",
       "19      0      0  1.624074  \n",
       "31      0      0  1.623637  \n",
       "17     32      0  1.622833  \n",
       "35     32      0  1.622653  \n",
       "2      32      0  1.622080  \n",
       "9      64     32  1.620063  \n",
       "22      0      0  1.619275  \n",
       "15     64     32  1.613999  \n",
       "20     32      0  1.606919  \n",
       "33     64     32  1.605523  \n",
       "34      0      0  1.604115  \n",
       "23     32      0  1.596219  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['auc2acc'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best arch is #12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
